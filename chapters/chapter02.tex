\section{Complex Matrices}

\begin{definition}[Conjugate Matrix]
	A \emph{conjugate matrix} is a matrix $\bar{E}$ obtained from $E$ by taking the complex conjugate of every entry of $E$.
\end{definition}

\begin{definition}[Coninvolutory Matrix]
	A matrix is said to be \emph{coninvolutory} if $E\bar{E} = I_n$ for $E \in \Mc{n}$.
\end{definition}

\begin{remark}
	By manipulation, we obtain $E^{-1} = \bar{E}$. Hence, we may also say that a matrix whose inverse is its own conjugate matrix is a coninvolutory matrix. Furthermore, we see that coninvolutory matrices are the extension of complex numbers with modulus 1 \cite{stamaria}.
\end{remark}

\begin{definition}[Skew-Coninvolutory Matrix]
	A matrix is said to be \emph{skew-coninvolutory} if $E\bar{E} = -I_n$ for $E \in \Mc{n}$.
\end{definition}

\begin{remark}
	Again, we may say that a matrix whose inverse is the negative of its own conjugate matrix is a skew-coninvolutory matrix. This is analogous to the skew-symmetric matrices we've encountered in linear algebra.
\end{remark}

\begin{theorem} \label{detbar}
	For a matrix $E \in \Mc{n}$, $det(\bar{E}) = \overline{det(E)}$.
}
\end{theorem}

\begin{proof}
	We prove by mathematical induction. 
	\newline
	\newline \textbf{Base Case}: 
	For $E$ = 
	\begin{pmatrix}
		\bar{a} & \bar{b} \\
		\bar{c} & \bar{d}
	\end{pmatrix}, 
	$det(\bar{E})$ & =
	\begin{vmatrix}
		\bar{a} & \bar{b} \\
		\bar{c} & \bar{d}
	\end{vmatrix} $= \overline{ad} - \overline{bc} = \overline{ad-bc} = \overline{det(E)}$
	\newline
	\newline
	\textbf{Induction Hypothesis}:
	Suppose $det(\bar{E}) = \overline{det(E)}$ holds for $E \in \Mc{n}$.
	\newline
	Let $X \in \Mc{n+1}$. Then, $$det(\overline{X}) = \overline{\sum_{j=1}^{n+1} a_{ij}c_{ij}} = \sum_{j=1}^{n+1} \overline{a_{ij}}\text{ }\overline{c_{ij}}$$ is the $i^{th}$ row expansion of an $(n+1)\times (n+1)$ matrix where $\overline{c_{ij}}$ is the cofactor of $\overline{a_{ij}}$.
	\newline
	Note that $\overline{c_{ij}} = (-1)^{i+j}\overline{M_{ij}}$ where $\overline{M_{ij}}$ is the determinant of the $n\times n$ matrix obtained by deleting the $i^{th}$ row and the $j^{th}$ column of the original matrix.
	\newline
	By I.H., $\overline{M_{ij}}$ is the determinant of an $n\times n$ conjugate matrix. Thus, we see that we are computing for the determinant of an $(n+1)\times (n+1)$ conjugate matrix. 
\end{proof}

\subsection{Skew-Coninvolutory Complex Matrices}

We now show and prove a result concerning whether or not $\mathscr{D}_n(\C)$ is empty when $n$ is odd as seen in \cite{stamaria}.

\begin{theorem}
	$\mathscr{D}_{n}(\C)$ is empty when $n$ is odd.
\end{theorem}

\begin{proof}
	If $E \in \mathscr{D}_{n}(\C)$ then $E\bar{E} = -I_n$. \newline Taking the determinant of both sides, 
	\begin{align*}
		det(E\bar{E}) &= det(-I_n) \\
		det(E)det(\bar{E}) &= (-1)^n \\
		det(E)\overline{det(E)} &= (-1)^n \text{, by Theorem \ref{detbar}} \\
		|det(E)|^2 &= (-1)^n
	\end{align*}
	Since $|det(E)|^2 > 0$, $(-1)^n > 0$. Hence, $n$ must be even.
\end{proof}

\section{Quaternion Basics}

\subsection{Multiplication and Addition}

Recall in Chapter 1 - the four-dimensional algebra of quaternions is generated by the basis elements $\{1,\ib,\jb,\kb\}$ such that 
\begin{equation} \label{quat_eq}
\ib^2 = \jb^2 = \kb^2 = \ib \jb \kb = -1
\end{equation}

From the above equation, we can easily derive the following:
\begin{align*}
	\jb\kb &= \ib & \kb\jb &= -\ib \\
	\kb\ib &= \jb & \ib\kb &= -\jb \\
	\ib\jb &= \kb & \jb\kb &= -\kb
\end{align*}

Notice that the quaternions are not commutative under \emph{multiplication}. In general, for quaternions $q_1 = a_1 + b_1\ib + c_1\jb + d_1\kb$ and $q_2 = a_2 + b_2\ib + c_2\jb + d_2\kb$, 
\begin{align*}
	q_1q_2 &= (a_1a_2 - b_1b_2 - c_1c_2 - d_1d_2) + (a_1b_2 + b_1a_2 + c_1d_2 - d_1c_2)\ib \\
		   &+ (a_1c_2 - b_1d_2 + c_1a_2 + d_1b_2)\jb + (a_1d_2 + b_1c_2 - c_1b_2 + d_1a_2)\kb
\end{align*}

%insert vector representation

Quaternions are, however, commutative under \emph{addition} where $q_1+q_2 = (a_1+a_2) + (b_1+b_2)\ib + (c_1+c_2)\jb + (d_1+d_2)\kb$.

\subsection{Other Operations and Properties}

\begin{definition}[$\HH$-Conjugate]
	The $\HH$-Conjugate of a quaternion $q = \quat{a}{b}{c}{d}$ is $\bar{q} = a - b\ib - c\jb - d\kb$.
\end{definition}

\begin{remark}
	Notice that $q\bar{q} = (\quat{a}{b}{c}{d})(a - b\ib -c\jb-d\kb) = a^2+b^2+c^2+d^2$.
\end{remark}

\begin{definition}[$\HH$-Norm]
	The $\HH$-Norm of a quaternion $q = \quat{a}{b}{c}{d}$ is $|q| = \sqrt{q\bar{q}} = \sqrt{a^2+b^2+c^2+d^2}$
\end{definition}

\begin{definition}[Inverse]
	The inverse of a quaternion $q$ is $q^{-1}$ such that $q^{-1}q = qq^{-1} = 1$.
\end{definition}

\begin{theorem}
For $q, p, r \in \HH$,
	\begin{enumerate}
		\item $|q|^2 = q\bar{q}$.
		\item If $q\neq 0$, then $q^{-1} = \bar{q}/|q|^2$.
		\item $\overline{qp} = \bar{p}\bar{q}$.
		\item $(qp)^{-1} = p^{-1}q^{-1}$ provided that the inverses of $p$ and $q$ exist.
		\item $(qp)r = q(pr)$ that is, quaternion multiplication is associative.
	\end{enumerate}
\end{theorem}

%insert proof here.

\begin{remark}
	Notice that most of the properties we see in quaternions are merely extensions of the properties we see in complex numbers. 
\end{remark}

\subsection{Quaternionic Matrices}

Most of the definitions we've already mentioned for complex matrices can also be extended in the context of quaternionic matrices.

\begin{definition}[Conjugate Quaternionic Matrix]
	A \emph{conjugate quaternionic matrix} is a matrix $\bar{E}$ obtained from $E$ by taking the $\HH$-conjugate of every entry of $E$.
\end{definition}

\begin{definition}[Skew-Coninvolutory Quaternionic Matrix]
	A quaternionic matrix $E$ is said to be \emph{Skew-Coninvolutory} if $E\bar{E} = -I_n$.
\end{definition}

\section{Matrix Homomorphisms}

We look into functions that make it possible for us to represent complex numbers and quaternions as matrices. These functions are of extreme importance as they are used to define some of the quaternionic determinants we will encounter.

\subsection{Representing Complex Numbers as Real Matrices}

In abstract algebra, we saw that we can define an isomorphism from the field of complex numbers to the 2D-plane ($\R^2$) - a mapping $\Theta : \C \rightarrow \R^2$ where a complex number $a+b\ib$ is mapped to a vector/point $(a,b)$ in the 2D-plane. Therefore, in order to represent complex numbers as real matrices, we have to find a way to view them as linear transformations over $\R^2$. 

Consider the complex function $f(z) = (a+b\ib)z$. We see that the images of $1$ and $\ib$ are $a+b\ib$ and $-b+a\ib$ respectively. Under the isomorphism $\Theta$ (in which case $1$ is mapped to $(1,0)$ while $\ib$ is mapped to $(0,1)$), we seek a matrix in $\Mr{2}$ that maps $(1,0)$ to $\Theta(a+b\ib) = (a,b)$ and $(0,1)$ to $\Theta(-b+a\ib) = (-b,a)$. 
\\
\noindent Let this matrix be $F$ = \begin{pmatrix} \alpha & \beta \\ \chi & \delta \end{pmatrix} where $\alpha, \beta, \chi, \text{ and } \delta \in \R$. Then, 
\begin{equation*}
	\begin{pmatrix} 
		\alpha & \beta \\ 
		\chi & \delta 
	\end{pmatrix} 
	\begin{pmatrix} 
		1 \\ 0 
	\end{pmatrix} = 
	\begin{pmatrix} a \\ b \end{pmatrix} \implies
	\begin{pmatrix}
		\alpha \\ \chi
	\end{pmatrix} =
	\begin{pmatrix} a \\ b \end{pmatrix} \implies 
	\alpha = a; \chi = b \text{ and}

	\begin{pmatrix} 
		\alpha & \beta \\ 
		\chi & \delta 
	\end{pmatrix} 
	\begin{pmatrix} 
		0 \\ 1 
	\end{pmatrix} = 
	\begin{pmatrix} -b \\ a \end{pmatrix} \implies
	\begin{pmatrix}
		\beta \\ \delta
	\end{pmatrix} =
	\begin{pmatrix} -b \\ a \end{pmatrix} \implies
	\beta = -b; \delta = a \\
\end{equation*}
\\
\noindent Therefore, $F$ = \begin{pmatrix} \alpha & \beta \\ \chi & \delta \end{pmatrix} = \begin{pmatrix} a & -b \\ b & a \end{pmatrix}. The matrix $F$ can be seen as the matrix representation of the function $f$ which is defined by multiplying a complex number $z$ by $a+b\ib$. We can therefore see the matrix $F$ as the real matrix representation of the complex number $a+b\ib$.

\begin{remark}
	Notice that the column vectors of the matrix $F$ are where the vectors $(1,0)$ and $(0,1)$ are mapped to. This pattern shows up in most of the matrices that we will be dealing with - the column vectors of a matrix are the images of the basis vectors under the linear transformation.
\end{remark}

\subsection{Homomorphisms from $\Mc{n}$ to $\Mr{2n}$}

In the previous subsection, we saw that we can represent complex numbers as $2\times 2$ real matrices. We can then define a mapping from $\C$ to $\Mr{2}$. We can also show that this mapping is a homomorphism.

\begin{theorem}
	Let $\phi : \C \rightarrow \Mr{2}$ such that $a+b\ib \mapsto$ \begin{pmatrix} a & -b \\ b & a \end{pmatrix}. Then $\phi$ is an injective homomorphism from $\C$ to $\Mr{2}.
\end{theorem}

%\begin{proof}
%	Let $z_1 = a+b\ib$ and $z_2 = c+d\ib \in \C$ . \\
%	Then $\phi(z_1z_2) = \phi[(a+b\ib)(c+d\ib)] = \phi[(ac-bd)+(ad+bc)\ib] = $\begin{pmatrix} (ac-bd) & -(ad+bc) \\ (ad+bc) & (ac-bd)$ \end{pmatrix}. \\ \\
%	Now, $\phi(z_1)\phi(z_2) = \phi[(a+b\ib)]\phi[(c+d\ib)] = $\begin{pmatrix} a & -b \\ b & a \end{pmatrix}\begin{pmatrix} c & -d \\ d & c \end{pmatrix}$ = $\begin{pmatrix} (ac-bd) & -(ad+bc) \\ (ad+bc) & (ac-bd)$ \end{pmatrix}. \\
%	Hence, $\phi(z_1z_2) = \phi(z_1)\phi(z_2)$.
%\end{proof}

\begin{remark}
	We will not include the proof for this theorem as this is merely a special case of Theorem \ref{phimorph} (when $n = 1$). 
\end{remark}

We will extend the definition of $\phi$ to hold for complex matrices in general. To do this, notice that every complex matrix can be represented as the sum of a real matrix and a purely imaginary matrix, i.e., for an $n\times n$ matrix $N$, $N = C + D\ib$ where $C,D \in \Mr{n}$. We see that we can intuitively extend the definition of $\phi$ by defining \begin{equation*} \phi(C+D\ib) = \begin{pmatrix} C & -D \\ D & C \end{pmatrix}  \cite{aslaksen}\end{equation*}

\noindent Alternatively, we can define a matrix \begin{equation*} J = \begin{pmatrix} 0 & -I_n \\ I_n & 0 \end{pmatrix} \end{equation*} and define $\phi$ more generally as $\phi(\Mc{n}) = \{P \in \Mr{2n} | JP = PJ\}$. 

Before we prove that the mapping $\phi$ is a homomorphism, we first prove that the left distributive laws hold for matrices in $\Mc{n}$.

\begin{theorem}\label{distributive}
	For matrices $A,B,C \in \Mc{n}$, $A(B+C) = AB + AC$.
}
\end{theorem}

\begin{proof}
	Let $A = [a_{ij}]$, $B = [b_{ij}]$, $C = [c_{ij}] \in \Mc{n}$. Then $B+C = [b_{ij}+c_{ij}]$ and \begin{equation} 
	\begin{align*} 
	A(B+C) &= [\sum_{k=1}^{n}a_{ik}(b_{kj}+c_{kj})] = [\sum_{k=1}^{n}(a_{ik}b_{kj}+a_{ik}c_{kj})] \\ 
	&= [\sum_{k=1}^{n}a_{ik}b_{kj} + \sum_{k=1}^{n}a_{ik}c_{kj}] = [\sum_{k=1}^{n}a_{ik}b_{kj}] + [\sum_{k=1}^{n}a_{ik}c_{kj}] = AB + AC 
	\end{align*} \end{equation}
\end{proof}

\begin{remark}
	The same method of proof can be used for the right distributive law. Furthermore, this also holds for matrices in $\Mr{n}$ and $\Mh{n}$.
\end{remark}

\begin{theorem} \label{phimorph}
	Let $\phi: \Mc{n} \rightarrow \Mr{2n}$ such that $C+D\ib \mapsto $ \begin{pmatrix} C & -D \\ D & C \end{pmatrix} where $C+D\ib \in \Mc{n}$. Then $\phi$ is an injective homomorphism. 
\end{theorem}

\begin{proof}
	\textbf{\newline1-1:}
	\begin{equation*}
		\phi(A+B\ib) = \phi(C+D\ib)
		&\implies \begin{pmatrix}A & -B \\ B & A \end{pmatrix} = \begin{pmatrix}C & -D \\ D & C \end{pmatrix}
	\end{equation*}
	\begin{align*}
		\implies A = C \text{ and } B = D \text{ by Matrix Equality}
		\implies A+B\ib = C+D\ib
		\implies \phi \text{ is injective.}
	\end{align*}
	\textbf{Homomorphism: \newline}
	Let $A+B\ib$, $C+D\ib \in \Mc{n}$. Then \begin{align*}
		\phi[(A+B\ib)(C+D\ib)] &= \phi[(A+B\ib)C+(A+B\ib)D\ib] \text{ by Theorem \ref{distributive}} \\
		&= \phi[AC+BC\ib+AD\ib-BD] = \phi[(AC-BD)+(BC+AD)\ib] \\
		&= \begin{pmatrix} (AC-BD) & -(BC+AD) \\ (BC+AD) & (AC-BD) \end{pmatrix}
	\end{align*}
		$\phi[(A+B\ib)]\phi[(C+D\ib)]$ = \begin{pmatrix}A & -B \\ B & A \end{pmatrix}\begin{pmatrix}C & -D \\ D & C \end{pmatrix} \newline \\ = \begin{pmatrix} \genmat{a} & \genmat{-b} \\ \genmat{b} & \genmat{a} \end{pmatrix}\begin{pmatrix} \genmat{c} & \genmat{-d} \\ \genmat{d} & \genmat{c} \end{pmatrix} \\  \\
	= \begin{pmatrix} 
	\genmatk{\sum_{k=1}^{n}a_{1k}c_{k1} - \sum_{k=1}^{n}b_{1k}d_{k1}}{-\sum_{k=1}^{n}a_{1k}d_{kn} - \sum_{k=1}^{n}b_{1k}c_{kn}}{\sum_{k=1}^{n}b_{nk}c_{k1} + \sum_{k=1}^{n}a_{nk}d_{k1}}{-\sum_{k=1}^{n}b_{nk}d_{kn} + \sum_{k=1}^{n}a_{nk}c_{kn}} 
	%\genmatk{\sum_{k=1}^{n}a_{1k}c_{k1} - \sum{k=1}^{n}b_{1k}d_{k1}}{\sum_{k=1}^{n}a_{1k}c_{kn} - \sum{k=1}^{n}b_{1k}d_{kn}}{\sum_{k=1}^{n}a_{nk}c_{k1} - \sum{k=1}^{n}b_{nk}d_{k1}}{\sum_{k=1}^{n}a_{nk}c_{kn} - \sum{k=1}^{n}b_{nk}d_{kn}} &
	%\genmatk{-(\sum_{k=1}^{n}a_{1k}d_{k1} + \sum_{k=1}^{n}b_{1k}c{k1})}{-(\sum_{k=1}^{n}a_{1k}d_{kn} + \sum_{k=1}^{n}b_{1k}c_{kn})}{-(\sum_{k=1}^{n}a_{nk}d_{k1} + \sum_{k=1}^{n}b_{nk}c{k1})}{-(\sum_{k=1}^{n}a_{nk}d_{kn} + \sum_{k=1}^{n}b_{nk}c_{kn})} \\
	%\genmatk{\sum_{k=1}^{n}a_{1k}d_{k1} + \sum_{k=1}^{n}b_{1k}c{k1}}{\sum_{k=1}^{n}a_{1k}d_{kn} + \sum_{k=1}^{n}b_{1k}c_{kn}}{\sum_{k=1}^{n}a_{nk}d_{k1} + \sum_{k=1}^{n}b_{nk}c{k1}}{\sum_{k=1}^{n}a_{nk}d_{kn} + \sum_{k=1}^{n}b_{nk}c_{kn}} &
	%\genmatk{\sum_{k=1}^{n}a_{1k}c_{k1} - \sum{k=1}^{n}b_{1k}d_{k1}}{\sum_{k=1}^{n}a_{1k}c_{kn} - \sum{k=1}^{n}b_{1k}d_{kn}}{\sum_{k=1}^{n}a_{nk}c_{k1} - \sum{k=1}^{n}b_{nk}d_{k1}}{\sum_{k=1}^{n}a_{nk}c_{kn} - \sum{k=1}^{n}b_{nk}d_{kn}}
	\end{pmatrix} \\ \\
	= \begin{pmatrix} (AC-BD) & -(BC+AD) \\ (BC+AD) & (AC-BD) \end{pmatrix}
\end{proof}

\subsection{Representing Quaternions as Complex Matrices}

A quaternion $q = a + b\ib + c\jb + d\kb$ can be written as $q = (a+b\ib) + (c+d\ib)\jb = (a+b\ib) + (d-c\ib)\kb$ where $a+b\ib,c+d\ib,d-c\ib \in \C$. We can therefore view the set of quaternions as a two-dimensional algebra over $\C$ \cite{stamaria}, i.e., we can define a mapping $\Omega : \HH \rightarrow \C^2$ such that $\quat{a}{b}{c}{d} \mapsto (a+b\ib,c+d\ib)$. We can easily show that $\Omega$ is an isomorphism.

\begin{theorem}
	Let $\Omega : \HH \rightarrow \C^2$ such that $\quat{a}{b}{c}{d} \mapsto (a+b\ib,c+d\ib)$. Then $\Omega$ is an isomorphism.
\end{theorem}

\begin{proof}
	\textbf{1-1: }
	\begin{align*}
		&\Omega(\quat{a}{b}{c}{d}) = \Omega(\quat{e}{f}{g}{h})
		\implies (a+b\ib,c+d\ib) = (e+f\ib,g+h\ib) \\
		&\implies a+b\ib = e+f\ib \text{ and } c+d\ib = g+h\ib
		\implies a = e, b = f, c = g, \text{ and } d = h \\
		&\implies \quat{a}{b}{c}{d} = \quat{e}{f}{g}{h}
		\implies \Omega \text{ is injective.}
	\end{align*}
	\textbf{Onto: }
	We show that $\forall (a+b\ib,c+d\ib) \in \C^2 \exists q \in \HH$ such that $\Omega(q) = (a+b\ib,c+d\ib)$. 
	Let $(a+b\ib,c+d\ib) \in \C^2$. Take $q = \quat{a}{b}{c}{d}$. Then $\Omega(q) = \Omega(\quat{a}{b}{c}{d}) = (a+b\ib,c+d\ib)$.
	
	\noindent \textbf{Homomorphism: }
	Let $q_1 = \quat{a_1}{b_1}{c_1}{d_1}$, $q_2 = \quat{a_2}{b_2}{c_2}{d_2} \in \HH$. Then,
	$\Omega(q_1q_2) = \Omega((\quat{a_1}{b_1}{c_1}{d_1})(\quat{a_2}{b_2}{c_2}{d_2})) = \Omega(\quat{a_1a_2-b_1b_2-c_1c_2-d_1d_2}{a_1b_2+b_1a_2+c_1d_2-d_1c_2}{a_1c_2-b_1d_2+c_1a_2+d_1b_2}{a_1d_2+b_1c_2-c_1b_2+d_1a_2}) = ((a_1a_2-b_1b_2-c_1c_2-d_1d_2)+(a_1b_2+b_1a_2+c_1d_2-d_1c_2)\ib, (a_1c_2-b_1d_2+c_1a_2+d_1b_2)+(a_1d_2+b_1c_2-c_1b_2+d_1a_2)\ib)$.
\end{proof}


\subsection{Homomorphisms from $\Mh{n}$ to $\Mc{2n}$}